/**
 * Lab 3 - Prompt Engineering
 * Teste diffÃ©rentes variations de prompts et compare les rÃ©sultats
 */

import { AzureOpenAI } from "openai";
import dotenv from "dotenv";
import fs from "fs";

dotenv.config();

// Charger les prompts depuis le fichier JSON
const promptsData = JSON.parse(fs.readFileSync("lab3-prompts.json", "utf-8"));
const prompts = promptsData.prompts;

// RÃ©sultats des tests
const results = [];

/**
 * Teste un prompt avec Azure OpenAI
 */
async function testPromptWithAzure(promptObj) {
  console.log(`\nğŸ”¬ Test: ${promptObj.nom}`);
  console.log(`ğŸ“ Description: ${promptObj.description}`);
  console.log(`â”€`.repeat(70));

  const startTime = Date.now();

  try {
    const endpoint = process.env.AZURE_OPENAI_ENDPOINT;
    const apiKey = process.env.AZURE_OPENAI_API_KEY;
    const apiVersion = process.env.AZURE_OPENAI_API_VERSION;
    const deployment = process.env.AZURE_OPENAI_DEPLOYMENT;

    const client = new AzureOpenAI({ endpoint, apiKey, deployment, apiVersion });

    const response = await client.chat.completions.create({
      messages: [
        { role: "user", content: promptObj.prompt }
      ],
      max_completion_tokens: 1000
    });

    const endTime = Date.now();
    const duration = ((endTime - startTime) / 1000).toFixed(1);

    const content = response.choices[0].message.content;
    const tokens = response.usage.total_tokens;

    console.log(`âœ… TerminÃ© en ${duration}s`);
    console.log(`ğŸ“Š Tokens: ${tokens}`);
    console.log(`ğŸ“„ RÃ©ponse (${content.length} caractÃ¨res):\n`);
    console.log(content);
    console.log(`\n${"â”€".repeat(70)}\n`);

    results.push({
      id: promptObj.id,
      nom: promptObj.nom,
      description: promptObj.description,
      prompt: promptObj.prompt,
      reponse: content,
      temps: duration + "s",
      tokens: tokens,
      longueur: content.length,
      structure: analyzeStructure(content),
      qualite: null, // Ã€ Ã©valuer manuellement
      error: null
    });

    return content;
  } catch (error) {
    const endTime = Date.now();
    const duration = ((endTime - startTime) / 1000).toFixed(1);

    console.log(`âŒ Erreur: ${error.message}\n`);

    results.push({
      id: promptObj.id,
      nom: promptObj.nom,
      description: promptObj.description,
      prompt: promptObj.prompt,
      reponse: "",
      temps: duration + "s",
      tokens: 0,
      longueur: 0,
      structure: "",
      qualite: null,
      error: error.message
    });

    return null;
  }
}

/**
 * Analyse la structure de la rÃ©ponse
 */
function analyzeStructure(text) {
  const features = [];

  if (text.includes('\n\n')) features.push("paragraphes");
  if (/^[â€¢\-\*]\s/m.test(text)) features.push("puces");
  if (/^\d+\.\s/m.test(text)) features.push("numÃ©rotation");
  if (/\*\*[^*]+\*\*/.test(text)) features.push("mise en gras");
  if (text.split('\n\n').length >= 3) features.push("multi-paragraphes");

  const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
  if (sentences.length <= 5) features.push("concis");
  else if (sentences.length > 10) features.push("dÃ©taillÃ©");

  return features.join(", ") || "texte simple";
}

/**
 * GÃ©nÃ¨re un tableau comparatif en markdown
 */
function generateMarkdownTable() {
  let markdown = `# Lab 3 â€” Prompt Engineering - RÃ©sultats\n\n`;
  markdown += `## Objectif\n`;
  markdown += `Tester diffÃ©rentes variations de prompts et comparer leur efficacitÃ©.\n\n`;
  markdown += `**Date:** ${new Date().toLocaleDateString('fr-FR')}\n`;
  markdown += `**ModÃ¨le testÃ©:** GPT-4 Mini (Azure OpenAI)\n\n`;
  markdown += `---\n\n`;

  markdown += `## ğŸ“Š Tableau Comparatif\n\n`;
  markdown += `| ID | Nom du Prompt | Temps | Tokens | Longueur | Structure | QualitÃ© (1-5) |\n`;
  markdown += `|----|---------------|-------|--------|----------|-----------|---------------|\n`;

  results.forEach(r => {
    if (r.error) {
      markdown += `| ${r.id} | ${r.nom} | ${r.temps} | ERREUR | - | - | - |\n`;
    } else {
      markdown += `| ${r.id} | ${r.nom} | ${r.temps} | ${r.tokens} | ${r.longueur} car | ${r.structure} | Ã€ Ã©valuer |\n`;
    }
  });

  markdown += `\n---\n\n`;
  markdown += `## ğŸ“ Analyse DÃ©taillÃ©e\n\n`;

  results.forEach((r, index) => {
    if (!r.error) {
      markdown += `### ${index + 1}. ${r.nom}\n\n`;
      markdown += `**Description:** ${r.description}\n\n`;
      markdown += `**Prompt utilisÃ©:**\n`;
      markdown += `\`\`\`\n${r.prompt}\n\`\`\`\n\n`;
      markdown += `**RÃ©ponse obtenue:**\n`;
      markdown += `> ${r.reponse.split('\n').join('\n> ')}\n\n`;
      markdown += `**Observations:**\n`;
      markdown += `- Temps de rÃ©ponse: ${r.temps}\n`;
      markdown += `- Tokens utilisÃ©s: ${r.tokens}\n`;
      markdown += `- Longueur: ${r.longueur} caractÃ¨res\n`;
      markdown += `- Structure: ${r.structure}\n\n`;
      markdown += `**Points Ã  Ã©valuer:**\n`;
      markdown += `- [ ] Respect des consignes du prompt\n`;
      markdown += `- [ ] ClartÃ© et prÃ©cision\n`;
      markdown += `- [ ] Adaptation au public cible\n`;
      markdown += `- [ ] QualitÃ© globale (1-5)\n\n`;
      markdown += `---\n\n`;
    }
  });

  markdown += `## ğŸ¯ Comparaison des Approches\n\n`;
  markdown += `### Prompt Basique vs Prompt StructurÃ©\n\n`;
  markdown += `**Observations gÃ©nÃ©rales:**\n\n`;
  markdown += `1. **Prompt sans structure** (prompt1_basique):\n`;
  markdown += `   - Plus simple Ã  Ã©crire\n`;
  markdown += `   - RÃ©sultat moins prÃ©visible\n`;
  markdown += `   - Peut manquer de contexte\n\n`;
  markdown += `2. **Prompt avec rÃ´le** (prompt2_role):\n`;
  markdown += `   - Oriente le ton de la rÃ©ponse\n`;
  markdown += `   - AmÃ©liore la pertinence\n\n`;
  markdown += `3. **Prompt structurÃ© complet** (prompt3_complet):\n`;
  markdown += `   - Format [RÃ´le] + [Contexte] + [TÃ¢che] + [Format]\n`;
  markdown += `   - RÃ©sultats plus prÃ©visibles\n`;
  markdown += `   - Meilleur contrÃ´le du format de sortie\n\n`;
  markdown += `4. **Prompt technique** (prompt4_technique):\n`;
  markdown += `   - AdaptÃ© Ã  un public spÃ©cialisÃ©\n`;
  markdown += `   - Demande de format spÃ©cifique (listes)\n\n`;
  markdown += `5. **Prompt crÃ©atif** (prompt5_creatif):\n`;
  markdown += `   - Encourage l'utilisation d'analogies\n`;
  markdown += `   - AdaptÃ© Ã  la vulgarisation\n\n`;

  markdown += `---\n\n`;
  markdown += `## ğŸ’¡ Bonnes Pratiques IdentifiÃ©es\n\n`;
  markdown += `### Structure recommandÃ©e pour un prompt efficace:\n\n`;
  markdown += `1. **[RÃ´le]**: DÃ©finir qui est l'IA (professeur, expert, vulgarisateur...)\n`;
  markdown += `2. **[Contexte]**: PrÃ©ciser le public cible et la situation\n`;
  markdown += `3. **[TÃ¢che]**: DÃ©crire clairement ce qui est attendu\n`;
  markdown += `4. **[Format]**: SpÃ©cifier le format de sortie souhaitÃ©\n\n`;
  markdown += `### Avantages:\n`;
  markdown += `- âœ… RÃ©ponses plus cohÃ©rentes\n`;
  markdown += `- âœ… Meilleur contrÃ´le du ton et du style\n`;
  markdown += `- âœ… Format de sortie prÃ©visible\n`;
  markdown += `- âœ… Adaptation au public cible\n\n`;

  markdown += `---\n\n`;
  markdown += `## ğŸ“Œ Conclusions\n\n`;
  markdown += `### Quand utiliser quel type de prompt:\n\n`;
  markdown += `| Type de Prompt | Usage RecommandÃ© |\n`;
  markdown += `|----------------|------------------|\n`;
  markdown += `| **Basique** | Tests rapides, questions simples |\n`;
  markdown += `| **Avec RÃ´le** | Besoin d'un ton spÃ©cifique |\n`;
  markdown += `| **StructurÃ© Complet** | Production, rÃ©sultats prÃ©visibles |\n`;
  markdown += `| **Technique** | Documentation, public expert |\n`;
  markdown += `| **CrÃ©atif** | Vulgarisation, communication grand public |\n\n`;

  markdown += `### Prochaines Ã©tapes:\n\n`;
  markdown += `1. ComplÃ©ter l'Ã©valuation qualitÃ© (1-5) pour chaque prompt\n`;
  markdown += `2. Tester les mÃªmes prompts avec un modÃ¨le local (Gemma 2B) pour comparaison\n`;
  markdown += `3. Identifier le prompt le plus efficace selon le contexte d'usage\n`;

  return markdown;
}

/**
 * Sauvegarde les rÃ©sultats en JSON
 */
function saveResultsToJSON() {
  const output = {
    date: new Date().toISOString(),
    model: "GPT-4 Mini (Azure OpenAI)",
    results: results
  };

  fs.writeFileSync("lab3-results.json", JSON.stringify(output, null, 2));
  console.log("\nğŸ’¾ RÃ©sultats sauvegardÃ©s dans lab3-results.json");
}

/**
 * Fonction principale
 */
async function main() {
  console.log("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
  console.log("â•‘          Lab 3 - Prompt Engineering                           â•‘");
  console.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
  console.log(`\nğŸ“‹ ${prompts.length} prompts Ã  tester\n`);

  // Tester tous les prompts
  for (const prompt of prompts) {
    await testPromptWithAzure(prompt);
  }

  // GÃ©nÃ©rer le rapport markdown
  console.log("\nğŸ“Š GÃ©nÃ©ration du rapport...\n");
  const markdown = generateMarkdownTable();
  fs.writeFileSync("LAB3-RESULTATS.md", markdown);
  console.log("âœ… Rapport gÃ©nÃ©rÃ©: LAB3-RESULTATS.md");

  // Sauvegarder les rÃ©sultats en JSON
  saveResultsToJSON();

  console.log("\n" + "=".repeat(70));
  console.log("âœ… Lab 3 terminÃ©!");
  console.log("ğŸ“„ Consultez LAB3-RESULTATS.md pour le tableau comparatif complet");
  console.log("=".repeat(70) + "\n");
}

// ExÃ©cution
main();
